{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 6:  SVMs on an Extended  MNIST \n",
        "\n",
        "In addition to the concepts in the [MNIST demo](mnist_svm.ipynb), you will learn:\n",
        "\n",
        "* Use the `skimage` module for some basic pre-processing of images in machine learning\n",
        "* Run and test an SVM classifier on a dataset you have created\n",
        "* Perform error handling in python\n",
        "\nIn the [MNIST demo](mnist_svm.ipynb), we saw how SVMs can be used for the classic MNIST problem of digit recognition.  In this lab, we are going to extend the MNIST dataset by adding a number of non-digit letters and see if the classifier can distinguish the digits from the non-digits.  All non-digits will be lumped as a single 11-th class.  In image processing, this is called a 'detection' as opposed to 'classification' problem.  Detection is vital in OCR and related problems since the non useful characters must be rejected.  For this lab we will create a very simple version of this problem."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the MNIST data\n",
        "\nWe first import the standard modules"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn import linear_model, preprocessing"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, fetch the digits with `fetch_mldata` command as shown in the demo.  Save the digits data matrix and labels to variables `Xdig` and `ydig`.  Also, recall that the pixel values in `Xdig` are between 0 and 255.  Create a scaled version of `Xdig` called `Xdigs` where the components are between -1 and 1."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_mldata\n",
        "mnist_orig = fetch_mldata(\"MNIST original\")\n",
        "Xdig = mnist_orig.data\n",
        "ydig = mnist_orig.target\n",
        "Xdigs = Xdig - 255 / 255"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function `plt_digit` that plots the digits.  You can use the code from the demo.  Test the function by plotting four random digits.  Use the `plt.title` command to print the numeric label in `ydig` above each digit."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def plt_digit(x, y):\n",
        "    nrow = 28\n",
        "    ncol = 28\n",
        "    xsq = x.reshape((nrow,ncol))\n",
        "    plt.imshow(xsq,  cmap='Greys_r')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title(int(y))\n",
        "    \n",
        "nplt = 4\n",
        "nsamp = Xdigs.shape[0]\n",
        "Iperm = np.random.permutation(nsamp)\n",
        "\n",
        "# Plot the images using the subplot command\n",
        "for i in range(nplt):\n",
        "    ind = Iperm[i]\n",
        "    plt.subplot(1,nplt,i+1)\n",
        "    plt_digit(Xdigs[ind,:], ydig[ind])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<matplotlib.figure.Figure at 0x13aeee278>"
            ],
            "image/png": [
              "iVBORw0KGgoAAAANSUhEUgAAAWQAAABqCAYAAACLZivkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
              "AAALEgAACxIB0t1+/AAADeBJREFUeJzt3XmMVUUWx/FvCSoiKCKKS5TRyKjgBhIXFEdcUNRoBBUc\n",
              "4iBLIiquETdAsMEom0uARIkawX0JKgoEXFDBMKAYUIiKK8pkdERHhAE3qPmjrep69mv6dfd779a9\n",
              "/fskxjP1+naf3G5r6lbVPWWstYiISPK2SzoBERGppA5ZRCQS6pBFRCKhDllEJBLqkEVEIqEOWUQk\n",
              "EuqQRUQikcoO2RjT2hjzvDHmf8aYNcaYvyedU9YYY9obY342xjyWdC5ZY4zpa4z58I+/38+MMd2S\n",
              "zintjDEb//TPFmPM5KTzqqumSSdQT1OBX4G2wFHAbGPMCmvtqmTTypSpwDtJJ5E1xpjTgXFAH2Ap\n",
              "sHeyGWWDtbaFi40xLYBvgGeTy6h+UjdCNsbsDPQGRlprN1prFwGzgEuSzSw7jDF9gR+B15LOJYNu\n",
              "Byqstf+01m611v7LWvuvpJPKmN7Af4CFSSdSV6nrkIG/Ar9ba1cHbSuAjgnlkynGmF2ACuD6pHPJ\n",
              "GmNME6ALsIcx5lNjzFpjzBRjzE5J55Yx/YEZNoV1IdLYIbcAfvpT23qgZQK5ZNEY4CFr7dqkE8mg\n",
              "tsD2wAVANyqn2zoBI5JMKkuMMe2AvwHTk86lPtLYIW8EdvlT2y7AhgRyyRRjzFHAacA9SeeSUZv/\n",
              "+Pdka+2/rbXrgLuBsxLMKWsuARZZa79IOpH6SOOi3mqgqTGmvbX2kz/ajgS0oNdwJwN/Ab4yxkDl\n",
              "00gTY0wHa23nBPPKBGvtf40xa4HwUTp1j9WR+wdwV9JJ1JdJ4TQLxpinqPxDHkzlY98coKt2WTSM\n",
              "MaY5uU8fN1DZQV9urf0ukaQyxhhTAfQEzgZ+o3JB+g1r7chEE8sAY0xX4BVgL2ttKp+Y0zhCBrgC\n",
              "eJjKldTvqeww1Bk3kLV2E7DJ/W9jzEbgZ3XGRTUGaEPlk97PwDPAHYlmlB39gZlp7YwhpSNkEZEs\n",
              "SuOinohIJqlDFhGJhDpkEZFIqEMWEYmEOmQRkUjUadubMUZbMmphrTX1uU73tiDrrLV71PUi3duC\n",
              "1Ovegu5vgQq6vxohS5qsSTqBDNO9La2C7q86ZBGRSKhDFhGJRFpfnRZpdKZNmwbAwIEDfdvZZ58N\n",
              "wLx58xLJSYpLI2QRkUioQxYRiYSmLEQis912VeOka665xseDBg0CYP369b5NUxXZohGyiEgkUj1C\n",
              "7tmzp49nzZrl4yZNmgDQuXPVIRfLly/38VVXXQXAAQcc4NuefvppAJYsWVKaZEVq4UbGV1xxhW+b\n",
              "NGmSj12p3PHjx5c3MSkbjZBFRCKhDllEJBKpnLI488wzgfzTFKHLLrvMx61atfLxhRdeCOQungwd\n",
              "OhSAN954w7f16NGjOAmLFGDq1KlA7t9taOLEiQDcdVdqz/CUWmiELCISCXXIIiKRqNMhp0mW2Tv9\n",
              "9NN97B7ZOnXqVPSfE96PMWPG+Hj06NGFXt8oym/edNNNPr722mt9fOihhwLw448/luLHLrPWdqnr\n",
              "RTHf23D6YdiwYdU+f/nll318/vnnA7B169ZSpFKvewvlu79Nm1bNsPbu3RuAiooK39a+fftq18yf\n",
              "P9/HDz30EADPPvtsqVLcloLur0bIIiKRiH5Rr3nz5kDu3ssjjzyyzt9n06ZNPl65ciUAO++8s2/r\n",
              "2LEjAMZUDXBbtmxZ55+Tde6e3Xzzzb5t11139XGvXr0AePjhh8ubWIoMGTLEx1dffbWP3d/eggUL\n",
              "fNt5551XvsQictFFFwFw++23+7ZPPvnEx66oUj7hU274ZH3SSScBcMQRR/i2kSNHNjzZItIIWUQk\n",
              "EuqQRUQiEeWURTg5//rrrwOw7777Fnz9xo0bAbj88st9m5umAFixYgVQNR0C8PbbbwP1mw5Jqxdf\n",
              "fBHIXbx89913t3nNaaedBuROU4TefPPNImWXPd27dwdyX4du1qyZjx944AEARowYUd7EIhEuat5x\n",
              "xx3VPg8XMx955BEAhg8fvs3vedttt/nY7e/u0KFDQ9IsKY2QRUQiEc0IOVxAmzx5so8LHRm/8847\n",
              "PnbFWZYtW1ak7LLDvQ0GcM455wBw3XXXFXy9K8IU2rx5s4/XrVvXgOyy55BDDvGx28K20047+bZP\n",
              "P/3UxzfeeCMAGzZsKFN2cQm3+LkSo2vWVJ0NWp9So+HTX01vQMZEI2QRkUioQxYRiUTiUxYtWrQA\n",
              "ct+eKbSoz3fffefjW265xceFTlUcfPDBPs7yYl74hlO4L/PJJ58E4PPPP9/m9eFe2R133BHI3eu5\n",
              "ePFiH4enWUjuFI+bqvjtt998mzsFBBrvVIXz4Ycf5o0b4oQTTijK9ykXjZBFRCKhDllEJBKJTFmE\n",
              "+39nzpwJVO1vLcQvv/wCQNu2bRuUR5s2bRp0fVp069bNxwcddJCPC62re+edd/o4XzGqKVOmNCC7\n",
              "7Ah3T7jaxYcddphvc1MV/fr1820LFy4sU3aNU+vWrX3sXk13RZpipBGyiEgkEhkhuzfEAE499dRt\n",
              "fu3vv/8OVL1JBzBq1Kii5DF27NhqbeEI8Ndffy3Kz0naWWedlbf966+/rvGacP+mW8gLhcWaFi1a\n",
              "1IDssuPwww/3sXtLNCxW5Z4Gn3vuubzXu8JNNf2+XnjhBSB3UVC2LVysd/9t//DDD0mlUyuNkEVE\n",
              "IqEOWUQkEmWdsnD1SLt27brNrwsfh0855RQAli5dWrrEAuE0Rbi3OSvCV8xfe+21ap+7okHh3uPw\n",
              "MFjnvffe83Fjfl06XMi75557qn0eTi+4Qje77babbxs8eLCPXY3p8POQq92br/CO5BduIHDmzp2b\n",
              "QCaF0QhZRCQSZR0h5yuu4oTbf66//nofl6JA0IQJEwA45phjqn22atWqov+8pB144IE+nj59uo9d\n",
              "OcPw9/Hqq68CNZ+WsmXLFiD3LLPG7Nhjj/Xx8ccfX+3zcDvn999/D8CSJUt8W7gN8csvvwRynzjC\n",
              "UrThCTdSs7333tvHffr08bHbLhueQhIbjZBFRCKhDllEJBIln7IIK/rne+T66aefABg6dKhv++CD\n",
              "D4qex9133+1jt2AV7jl2p4zUtuCYduHj3H777QfAK6+84tvcVIV7vAbYfffdfewKEbmpjcaupgW2\n",
              "L774AsjdP798+XIgd5ri/fff9/GAAQOA3JNuwimLr776qggZZ9/zzz/v43AP/erVqwH47LPPyp5T\n",
              "oTRCFhGJhDpkEZFIlGTKIlx5Dvfyhq+ROmvXrgVKM01x3333+dgd6wRV+2rdqivAkCFDgOy8Lh16\n",
              "6aWXfBwe4XTDDTcA8NFHH/m2c889F6j5sNN8e20bo4svvhiA4447zreFh3C6v/twz6s7XDP8Ww+v\n",
              "d/W5+/bt69vCr502bVpRcs+6Vq1a+TjscxYsWJBEOnWiEbKISCRKMkIO9/7le1MmFJZ2LBa37/bS\n",
              "Sy/1bU2aNKn2daNHj/bxE088UfQ8YuGOTAeYNWuWj90eWVe0BmDOnDlA1UkuULXgCXD//feXKs1U\n",
              "6dy5M5A7AnOFsAAuuOACILd4llsoPfHEE33b9ttv7+MHH3wQyL33M2bM8HE4Apfq3ALo/vvv79vC\n",
              "30lY1CxWGiGLiERCHbKISCQSqYf88ccf+7hYjxHhPuP+/fsDNb/+6xbzVq5cWZSfnSZhLdhnnnkG\n",
              "gDPOOMO3uX3YYVGc7t27lym79Mh3eGY4/eCmLDZv3uzbjj76aAD22msv3+bKCUDVI3dYuGnSpElF\n",
              "yjj73IJ0uPfY7f0GmDdvXtlzqiuNkEVEIqEOWUQkEolMWaxfv97H4Qr+toSvkLZr1w7IfdSurX5v\n",
              "eFyR232Rhn2JpeRenQ6PFHKP3QMHDvRtpai4l3b5DnvNJzxI9t577wWqHq0hd/fPN998A0CvXr2K\n",
              "kWKjk69++eLFixPIpP40QhYRiUQiI+SwyFCnTp2qfR7uI7z11luB3IIs7kSFcA9oOGJxi3bhPuNw\n",
              "Aa+xj4wdNzIO6yG7xdFHH300kZzS4qmnngLy10AO1VZ7NywYdPLJJ1drk8K1bt0aKPzpJUYaIYuI\n",
              "REIdsohIJEoyZbFhwwYfh48PboqhY8eOvq1YC0bhsThjx44FYPbs2UX53lkSLii56aKZM2f6tvHj\n",
              "x5c9pzRye7jD6bUrr7zSx82aNat2jTuo9/HHH/dtkydPLlWKjUKbNm18nK94Wb62mGmELCISiZKM\n",
              "kEeNGuXjcNHDFVqpz/9rhUVC3FH28+fP921hkaIsltBsiKZNq37NEydO9LH7PYSjtPCATanZt99+\n",
              "C8CwYcN8WxhLeYRldd3TePhUnrYFPo2QRUQioQ5ZRCQSJd+H3KNHDx+7KQZXh7cQbk9x+FbeW2+9\n",
              "VaTsGodwP7Z7yxFgxIgRACxcuLDcKYkUxaBBg6q1bdmyxccTJkwoZzoNphGyiEgk1CGLiESirK9O\n",
              "h9MXUnr77LMPAAMGDPBtjz32mI/HjRtX9pxEiqFLly4A7LnnntU+Gz58uI/XrFlTtpyKQSNkEZFI\n",
              "JFJcSMqjX79+AOywww6+raKiIql0RIrGvSEZ/m2vXr0agLlz5yaSUzFohCwiEgl1yCIikTB1ebXQ\n",
              "GJOu9xATYK2tVzUT3duCLLPWdqnrRbq3BanXvQXd3wIVdH81QhYRiYQ6ZBGRSKhDFhGJhDpkEZFI\n",
              "1HUf8jogXa++lFe72r+kRrq3tavv/dW9rZ3+dkuroPtbp10WIiJSOpqyEBGJhDpkEZFIqEMWEYmE\n",
              "OmQRkUioQxYRiYQ6ZBGRSKhDFhGJhDpkEZFIqEMWEYnE/wHYp/Fr2fb/ogAAAABJRU5ErkJggg==\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 49,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exception Handling\n",
        "\n",
        "In the routines we will develop below, we will need to handle error conditions, called exceptions. A very nice description of how to perform exception handling in python is given in\n",
        "\n",
        "https://docs.python.org/3/tutorial/errors.html\n",
        "\nAs described there, errors are described by a class that derives from a base class Exception. When the error occurs, the program raises the exception with the raise command. The calling function can catch the exception with the try ... except control flow. We will define our exception as follows which has an optional string argument."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class ImgException(Exception):\n",
        "    def __init__(self, msg='No msg'):\n",
        "        self.msg = msg"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exceptions are used as follows:  First, when there is an error in some function, you `raise` the exception as follows:\n",
        "\n",
        "    foo():\n",
        "        ...\n",
        "        if (error):\n",
        "           raise ImgException(\"File not found\")\n",
        "           \n",
        "        # Code that will not execute if the error condition occured\n",
        "        \n",
        "     \n",
        "The function that calls `foo()` can catch the error using the following syntax:\n",
        "\n",
        "    try: \n",
        "        foo()\n",
        "        \n",
        "        # Continue processing in case when there was no exception\n",
        "        ....\n",
        "        \n",
        "    except ImgException as e:\n",
        "        print(\"foo() didn't work\")\n",
        "        print(\"Error msg = %s\" % e.msg)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Non-Digit Characters\n",
        "\nWe will now build a set of non-digit characters.  As a simple source, we will get hand-written lowercase letters 'a' to 'z' and process them with the `skimage` package.  The `skimage` module is a very powerful package that has a similar interface as OpenCV.  We first import the relevant modules."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg\n",
        "import skimage.io\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.segmentation import clear_border\n",
        "from skimage.measure import label, regionprops\n",
        "from skimage.morphology import closing, square\n",
        "from skimage.color import label2rgb\n",
        "from skimage.transform import resize\n",
        "import matplotlib.patches as mpatches\n",
        "from skimage import data\n",
        "import skimage"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can get a set of character images from a very nice website\n",
        "\n",
        "http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/\n",
        "\n",
        "Go to this website, and download the file `EnglishHnd.tgz`.  After you untar this file, there are a large number of `.png` files in the directory:\n",
        "\n",
        "    EnglishHnd\\English\\Hnd\\Img\n",
        "    \n",
        "Each directory has about 55 samples of hand-written letters and numbers.  After you have downloaded this file, complete the function `load_img` to load an image from a character and sample index.\n",
        "\n",
        "Alternatively, the files are available on Google Drive:\n",
        "\n",
        "https://drive.google.com/file/d/0BxOz-SM9a1h4UksxSXBjQ0dabUk/view?usp=sharing \n",
        "\n",
        "You can download and unzip the file.\n",
        "\nThe code at the end will test the function to see if it working correctly.  For one sample, it should print the image and a second it should say the file was not found."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "\n",
        "def load_img(char_ind, samp_ind):\n",
        "    \"\"\"\n",
        "    Returns the image from the dataset given a character and sample index.\n",
        "    \n",
        "        \n",
        "    If the file doesn't exist, it raises an Exception with the filename.   \n",
        "    \"\"\" \n",
        "    fname = \"Img/Sample\" + str(samp_ind).zfill(3) + \"/img\" + str(samp_ind).zfill(3) + \"-\" + str(char_ind).zfill(3) + \".png\"\n",
        "    if(os.path.isfile(fname)):\n",
        "        pass\n",
        "    else:\n",
        "        raise ImgException(fname + \" not found\")\n",
        "    img = skimage.io.imread(fname)\n",
        "    return img"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the `load_img` function.  This should:\n",
        "* Plot the image in `Sample047\\img047-006.png`\n",
        "* Say that the `Sample047\\img047-070.png` is not found."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "char_ind = 47\n",
        "samp_inds = [6,70]\n",
        "for samp_ind in samp_inds:\n",
        "    try:\n",
        "        img = load_img(char_ind=char_ind, samp_ind=samp_ind)\n",
        "        print(\"Char = %d samp=%d\" % (char_ind, samp_ind))\n",
        "        plt.imshow(img)\n",
        "    except ImgException as e:\n",
        "        print(e.msg)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Char = 47 samp=6\n",
            "Img/Sample070/img070-047.png not found\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<matplotlib.figure.Figure at 0x107957e48>"
            ],
            "image/png": [
              "iVBORw0KGgoAAAANSUhEUgAAAVYAAAD8CAYAAAAsX4y/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
              "AAALEgAACxIB0t1+/AAAFeVJREFUeJzt3W+MXNV9xvHvUztAQlL8JxuL2K5whBWKIgWcFTUiilIc\n",
              "CHYRdiuCQFHZULdbtbSFUCkxzYsqUitBG4UEqXJixUmXiBAIgdpCNMQ1pFVf4LAOxPwxxAsJeFeA\n",
              "NwScNjQJJL++uL+F8WJnZ3bP7NyZeT7SaM4999yZc2fWj++cuXeOIgIzMyvntzrdATOzXuNgNTMr\n",
              "zMFqZlaYg9XMrDAHq5lZYQ5WM7PC2hKski6Q9ISkMUlb2vEcZmZ1pdLnsUpaAPwAOA8YBx4ALouI\n",
              "x4o+kZlZTbXjiPUsYCwinoqIXwJfBza24XnMzGppYRseczlwsGF5HPi96Y0kDQPDACeeeOL7Tjvt\n",
              "tDZ0xcysOXv37v1xRAyUeKx2BGtTImIbsA1gcHAwRkdHO9UVMzMkPV3qsdoxFDABrGxYXpF1ZmZ9\n",
              "oR3B+gCwWtIqSccBlwI72/A8Zma1VHwoICJelfRXwD3AAuDLEfFo6ecxM6urtoyxRsTdwN3teGwz\n",
              "s7rzlVdmZoU5WM3MCnOwmpkV5mA1MyvMwWpmVpiD1cysMAermVlhDlYzs8IcrGZmhTlYzcwKc7Ca\n",
              "mRXmYDUzK8zBamZWmIPVzKwwB6uZWWEzBqukL0s6JOmRhrolknZJOpD3i7Nekm6UNCZpn6Q17ey8\n",
              "mVkdNXPE+q/ABdPqtgC7I2I1sDuXAdYDq/M2DGwt000zs+4xY7BGxH8BP5lWvREYyfIIsKmh/qao\n",
              "3A8sknRyqc6amXWD2Y6xLouIZ7P8HLAsy8uBgw3txrPOzKxvzPnLq4gIIFrdTtKwpFFJo5OTk3Pt\n",
              "hplZbcw2WJ+f+oif94eyfgJY2dBuRda9QURsi4jBiBgcGBiYZTfMzOpntsG6ExjK8hCwo6H+8jw7\n",
              "YC1wuGHIwMysL8w4/bWkW4APAm+XNA78PXAdcJukzcDTwCXZ/G5gAzAGvAxc0YY+m5nV2ozBGhGX\n",
              "HWPVuqO0DeDKuXbKzKyb+corM7PCHKxmZoU5WM3MCnOwmpkV5mA1MyvMwWpmVpiD1cysMAermVlh\n",
              "DlYzs8IcrGZmhTlYzcwKc7CamRXmYDUzK8zBamZWmIPVzKwwB6uZWWEzBquklZLuk/SYpEclXZX1\n",
              "SyTtknQg7xdnvSTdKGlM0j5Ja9q9E2ZmddLMEeurwN9GxOnAWuBKSacDW4DdEbEa2J3LAOuB1Xkb\n",
              "BrYW77WZWY3NGKwR8WxEfC/L/wPsB5YDG4GRbDYCbMryRuCmqNwPLJqa0dXMrB+0NMYq6RTgTGAP\n",
              "sKxhBtbngGVZXg4cbNhsPOumP9awpFFJo5OTky1228ysvpoOVklvBb4JXB0RP21cl5MIRitPHBHb\n",
              "ImIwIgYHBgZa2dTMrNaaClZJb6IK1Zsj4o6sfn7qI37eH8r6CWBlw+Yrss7MrC80c1aAgO3A/oj4\n",
              "bMOqncBQloeAHQ31l+fZAWuBww1DBmZmPW9hE23OAf4YeFjSQ1n3d8B1wG2SNgNPA5fkuruBDcAY\n",
              "8DJwRdEem5nV3IzBGhH/DegYq9cdpX0AV86xX2ZmXctXXpmZFeZgNTMrzMFqZlZYM19emXVUdWLK\n",
              "sVXD+mb14WC1tpopFEs+hwPW6sLBam8wH2HYDpIcrlYLHmO110jq2lCd0u39t97gYDWgtwKpl/bF\n",
              "upOD1RxEZoU5WPucQ9WsPAermVlhDtY+5qNVs/ZwsJqZFeZgNTMrzMFqZlZYMzMInCDpu5K+L+lR\n",
              "SZ/O+lWS9kgak3SrpOOy/vhcHsv1p7R3F2y2evUqpV7dL+sezRyx/gI4NyLeC5wBXJBTrlwP3BAR\n",
              "pwIvApuz/Wbgxay/IduZzQuHqtXBjMEalf/NxTflLYBzgduzfgTYlOWNuUyuXyd//WzzwKFqddHs\n",
              "LK0Lcr6rQ8Au4EngpYh4NZuMA8uzvBw4CJDrDwNLj/KYw5JGJY1OTk7ObS9s1noljHplP6w3NBWs\n",
              "EfGriDiDairrs4DT5vrEEbEtIgYjYnBgYGCuD2d9ICKOeTOrk5Z+NjAiXpJ0H3A2sEjSwjwqXQFM\n",
              "ZLMJYCUwLmkhcBLwQsE+Wxdy+Fk/aeasgAFJi7L8ZuA8YD9wH3BxNhsCdmR5Zy6T6+8N/6vqab/p\n",
              "SNJHlNaPmjliPRkYkbSAKohvi4i7JD0GfF3SPwAPAtuz/Xbgq5LGgJ8Al7ah32ZmtTVjsEbEPuDM\n",
              "o9Q/RTXeOr3+58BHivTOuoJ/ud/sSL7yyhyKZoU5WM3MCnOwmpkV5mA1MyvMwWpmVpiD1cysMAer\n",
              "mVlhDlYzs8IcrGZmhTlYzcwKc7CamRXmYDUzK8zBamZWmIPVzKwwB6vhuR7Nymo6WHNCwQcl3ZXL\n",
              "qyTtkTQm6VZJx2X98bk8lutPaU/XzczqqZUj1quopmSZcj1wQ0ScCrwIbM76zcCLWX9DtjMz6xvN\n",
              "Tn+9AvgD4Eu5LOBc4PZsMgJsyvLGXCbXr5M/a/Y0/1C22ZGaPWL9HPAJ4Ne5vBR4KWdoBRgHlmd5\n",
              "OXAQINcfzvZHkDQsaVTS6OTk5Cy7b2ZWP83M0nohcCgi9pZ84ojYFhGDETE4MDBQ8qHNzDqqmVla\n",
              "zwEukrQBOAH4beDzwCJJC/OodAUwke0ngJXAuKSFwEnAC8V7bmZWUzMesUbEtRGxIiJOoZrK+t6I\n",
              "+ChwH3BxNhsCdmR5Zy6T6+8ND8LVloe/zcqby3msnwSukTRGNYa6Peu3A0uz/hpgy9y6aGbWXZoZ\n",
              "CnhNRHwH+E6WnwLOOkqbnwMfKdA36wL+MGL2Rr7yysysMAdrH/P4qll7tDQUYDbdscLZQwTWzxys\n",
              "1hatHg07iK2XOFitFhqD2CFr3c7B2qfqPL46vW8OWus2DlarPR/NWrfxWQHWVSTV+mjbDBys1qUc\n",
              "sFZnDlbrag5YqyMHq/UEh6vViYPVeoaPXq0uHKzWcxyu1mkOVutJDlfrJAdrn+qH80EdrtYpzc7S\n",
              "+iNJD0t6SNJo1i2RtEvSgbxfnPWSdKOkMUn7JK1p5w7Y7DlczdqjlSPW34+IMyJiMJe3ALsjYjWw\n",
              "m9dnClgPrM7bMLC1VGetPIerWXlzGQrYCIxkeQTY1FB/U1Tup5p08OQ5PI+1mcPVrKxmgzWAb0va\n",
              "K2k465ZFxLNZfg5YluXlwMGGbcez7giShiWNShqdnJycRdetpIg44jabbaeX68bhavOl2R9heX9E\n",
              "TEh6B7BL0uONKyMiJLX0rykitgHbAAYHB+v5L7GPzSYcG7dpZnsHnfWqpo5YI2Ii7w8Bd1JNIvj8\n",
              "1Ef8vD+UzSeAlQ2br8g6syPM5Sh5thzmNh9mDFZJJ0p621QZOB94BNgJDGWzIWBHlncCl+fZAWuB\n",
              "ww1DBmbHNN8ha9YuzQwFLAPuzP/pFwJfi4hvSXoAuE3SZuBp4JJsfzewARgDXgauKN5r63lT4dqO\n",
              "I0xJDm9rqxmDNSKeAt57lPoXgHVHqQ/gyiK9s77XzoA1axdfeWVdofQRpoPa2snBal3DH9+tWzhY\n",
              "ras4XK0bOFit6zhcre4crNaVSoSrx1mtXRysZmaFOVita3lIwOrKwWpmVpiD1cysMAermVlhDlYz\n",
              "s8IcrGZmhTlYzcwKc7CamRXmYDUzK6ypYJW0SNLtkh6XtF/S2ZKWSNol6UDeL862knSjpDFJ+ySt\n",
              "ae8uWL/yJalWV80esX4e+FZEnEb1o9f7gS3A7ohYDezOZYD1wOq8DQNbi/bYzKzmmpnz6iTgA8B2\n",
              "gIj4ZUS8BGwERrLZCLApyxuBm6JyP7BoatJBM7N+0MwR6ypgEviKpAclfSknFVzWMEngc1RzYwEs\n",
              "Bw42bD+edUeQNCxpVNLo5OTk7PfA+lKJYQD/1oC1SzPBuhBYA2yNiDOBn/H6x37gtXmuWvorjYht\n",
              "ETEYEYMDAwOtbGpmVmvNBOs4MB4Re3L5dqqgfX7qI37eH8r1E8DKhu1XZJ1ZEf7SyupuxmCNiOeA\n",
              "g5LenVXrgMeAncBQ1g0BO7K8E7g8zw5YCxxuGDIwm5NSoephAGunGae/Tn8N3CzpOOAp4AqqUL5N\n",
              "0mbgaeCSbHs3sAEYA17OtmZmfaOpYI2Ih4DBo6xad5S2AVw5x36ZvYGHAKxb+Mor6wolQ9XDANZu\n",
              "DlarPR+pWrdxsFpf8dGqzQcHq9Waj1atGzV7VoDZvGpHoPpo1eaLg7WPHCus6hY4DlXrdg7WPjBT\n",
              "UEmqRfD4Y7/1Co+x9rhmw0pSR4Otnc9dh/80rL84WK3jHKrWaxysPWw2gTWfR62dPko2axcHa4+a\n",
              "S2DNR9jNx3P4aNU6xV9e2byaryNUh6p1koO1B9Xx4/V89smhap3mYLW26UTAO1StDhysVlynjpgd\n",
              "qlYXzczS+m5JDzXcfirpaklLJO2SdCDvF2d7SbpR0pikfZLWtH83bEonQm3q2/1OfsvvULU6aWZq\n",
              "lici4oyIOAN4H9WsAHdSTSi4OyJWA7t5fYLB9cDqvA0DW9vRcWuf3xRS00O0DuO5DlWrm1ZPt1oH\n",
              "PBkRTwMbgZGsHwE2ZXkjcFNU7gcWTU06aN3haOFZlxCdzqFqddRqsF4K3JLlZQ2TBD4HLMvycuBg\n",
              "wzbjWWdWlEPV6qrpYM2JBC8CvjF9Xc5z1dJfuaRhSaOSRicnJ1vZ1PpcRDhUrdZaOWJdD3wvIp7P\n",
              "5eenPuLn/aGsnwBWNmy3IuuOEBHbImIwIgYHBgZa77n1HQeqdYtWgvUyXh8GANgJDGV5CNjRUH95\n",
              "nh2wFjjcMGRgZtbzmjqPVdKJwHnAnzdUXwfcJmkz8DRwSdbfDWwAxqjOILiiWG9tRhFRyy+Z5sJH\n",
              "qdZtmgrWiPgZsHRa3QtUZwlMbxvAlUV6Z33NgWrdyr9uZbXkULVu5mDtQd0cSv6CynqBg7VHdVs4\n",
              "OVCtlzhYe1g3BJUD1XqRf92qx9XxLAEHqfU6H7H2gboEmY9OrV/4iLVPTAWaf8nfrP0crH2mMexK\n",
              "h6yD1KziYO1j04Ow1aB1kJodnYPVXuOgNCvDX16ZmRXmYDUzK8zBamZWmIPVzKwwB6uZWWFNBauk\n",
              "j0t6VNIjkm6RdIKkVZL2SBqTdGvOiYWk43N5LNef0s4dMDOrmxmDVdJy4G+AwYh4D7CAarbW64Eb\n",
              "IuJU4EVgc26yGXgx62/IdmZmfaPZoYCFwJslLQTeAjwLnAvcnutHgE1Z3pjL5Pp1qtuvgJiZtdGM\n",
              "wRoRE8BngGeoAvUwsBd4KSJezWbjwPIsLwcO5ravZvsjpnUxM+tlzQwFLKY6Cl0FvBM4Ebhgrk8s\n",
              "aVjSqKTRycnJuT6cmVltNDMU8CHghxExGRGvAHcA5wCLcmgAYAUwkeUJYCVArj8JeGH6g0bEtogY\n",
              "jIjBgYGBOe6GmVl9NBOszwBrJb0lx0rXAY8B9wEXZ5shYEeWd+Yyuf7e8EXoZtZHmhlj3UP1JdT3\n",
              "gIdzm23AJ4FrJI1RjaFuz022A0uz/hpgSxv6bWZWW6rDweTg4GCMjo52uhtm1sck7Y2IwRKP5Suv\n",
              "zMwKc7CamRXmYDUzK8zBamZWmIPVzKwwB6uZWWEOVjOzwhysZmaFOVjNzApzsJqZFeZgNTMrzMFq\n",
              "ZlaYg9XMrDAHq5lZYQ5WM7PCHKxmZoU1FaySrpL0iKRHJV2ddUsk7ZJ0IO8XZ70k3ShpTNI+SWva\n",
              "uQNmZnXTzCyt7wH+DDgLeC9woaRTqaZc2R0Rq4HdvD4Fy3pgdd6Gga1t6LeZWW01c8T6u8CeiHg5\n",
              "Il4F/hP4I6opsUeyzQiwKcsbgZuicj/VbK4nF+63mVltLZy5CY8A/yhpKfB/wAZgFFgWEc9mm+eA\n",
              "ZVleDhxs2H48655tqEPSMNURLcAvJD0yqz2oj7cDP+50J+bA/e+sbu8/dP8+vLvUA80YrBGxX9L1\n",
              "wLeBnwEPAb+a1iYktTQrYURso5rtFUmjpSbx6pRu3wf3v7O6vf/Q/fsgqdiMpk19eRUR2yPifRHx\n",
              "AeBF4AfA81Mf8fP+UDafAFY2bL4i68zM+kKzZwW8I+9/h2p89WvATmAomwwBO7K8E7g8zw5YCxxu\n",
              "GDIwM+t5zYyxAnwzx1hfAa6MiJckXQfcJmkz8DRwSba9m2ocdgx4Gbiiicff1lq3a6nb98H976xu\n",
              "7z90/z4U678iWhoaNTOzGfjKKzOzwhysZmaFdTxYJV0g6Ym8BHbLzFvMP0krJd0n6bG8rPeqrO+q\n",
              "y3olLZD0oKS7cnmVpD3Zz1slHZf1x+fyWK4/pZP9zj4tknS7pMcl7Zd0dhe+/h/Pv59HJN0i6YQ6\n",
              "vweSvizpUOM55rN5zSUNZfsDkoaO9lzzvA//nH9H+yTdKWlRw7prcx+ekPThhvrWcioiOnYDFgBP\n",
              "Au8CjgO+D5zeyT4do58nA2uy/Daq081OB/4J2JL1W4Drs7wB+HdAwFqqK9fqsB/XUJ3RcVcu3wZc\n",
              "muUvAH+R5b8EvpDlS4Fba9D3EeBPs3wcsKibXn+qi2R+CLy54bX/WJ3fA+ADwBrgkYa6ll5zYAnw\n",
              "VN4vzvLiDu/D+cDCLF/fsA+nZwYdD6zKbFowm5zq9B/b2cA9DcvXAtd2sk9N9nsHcB7wBHBy1p0M\n",
              "PJHlLwKXNbR/rV0H+7yC6jcdzgXuyn8AP274A3vtvQDuAc7O8sJspw72/aQMJU2r76bXf+qKxCX5\n",
              "mt4FfLju7wFwyrRQauk1By4DvthQf0S7TuzDtHV/CNyc5SPyZ+o9mE1OdXoo4FiXv9ZWfiQ7E9hD\n",
              "65f1dtLngE8Av87lpcBLUf3+AxzZx9f6n+sPZ/tOWQVMAl/JoYwvSTqRLnr9I2IC+AzwDNXl3YeB\n",
              "vXTPezCl1de8du/FNH9CdaQNBfeh08HaVSS9FfgmcHVE/LRxXVT/ldXy3DVJFwKHImJvp/sySwup\n",
              "Ps5tjYgzqS6tPmKcq86vP0CORW6k+k/incCJwAUd7dQc1f01n4mkTwGvAjeXfuxOB2vXXP4q6U1U\n",
              "oXpzRNyR1d1yWe85wEWSfgR8nWo44PNUvzw2dZFIYx9f63+uPwl4YT47PM04MB4Re3L5dqqg7ZbX\n",
              "H+BDwA8jYjIiXgHuoHpfuuU9mNLqa17H9wJJHwMuBD6a/0FAwX3odLA+AKzOb0aPoxqk39nhPr2B\n",
              "JAHbgf0R8dmGVV1xWW9EXBsRKyLiFKrX+N6I+ChwH3BxNpve/6n9ujjbd+zIJCKeAw5Kmvr1oXXA\n",
              "Y3TJ65+eAdZKekv+PU3tQ1e8Bw1afc3vAc6XtDiP2s/Puo6RdAHVsNhFEfFyw6qdwKV5RsYqqt+U\n",
              "/i6zyan5Hgw/yuDxBqpv2Z8EPtXp/hyjj++n+sizj+rXvR7Kfi+l+kLoAPAfwJJsL+Bfcp8eBgY7\n",
              "vQ8N+/JBXj8r4F35hzMGfAM4PutPyOWxXP+uGvT7DKqfq9wH/BvVN8xd9foDnwYep/opzq9Sfftc\n",
              "2/cAuIVqPPgVqk8Nm2fzmlONY47l7Yoa7MMY1Zjp1L/lLzS0/1TuwxPA+ob6lnLKl7SamRXW6aEA\n",
              "M7Oe42A1MyvMwWpmVpiD1cysMAermVlhDlYzs8IcrGZmhf0/u+QMo0ZNSzcAAAAASUVORK5CYII=\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 44,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The images in the sample directory have very high resolution.  Complete the following method to find the image and place it in a 28 x 28 box.  You can look at this very nice demo of the `skimage` methods here:\n",
        "\n",
        "http://scikit-image.org/docs/dev/auto_examples/segmentation/plot_label.html\n",
        "\nThe code is somewhat complex, so I have provided some of the steps, esp. for the thresholding."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_resize(img):\n",
        "    \"\"\"\n",
        "    Extracts a character from the image, and places in a 28x28 image to match the MNIST format.\n",
        "    \n",
        "    Returns:\n",
        "    img1:  MNIST formatted 28 x 28 size image with the character from img\n",
        "    box:   A bounding box indicating the locations where the character was found in img.    \n",
        "    \"\"\"\n",
        "    # Image sizes (fixed for now).  To match the MNIST data, the image \n",
        "    # will be first resized to 20 x 20.  Then, the image will be placed in center of 28 x 28 box\n",
        "    # offet by 4 on each side.\n",
        "    nx_img = 20   \n",
        "    ny_img = 20\n",
        "    nx_box = 28   \n",
        "    ny_box = 28\n",
        "    offx = 4\n",
        "    offy = 4\n",
        "    \n",
        "    # TODO:  Convert the image to gray scale using the skimage.color.rgb2gray method.\n",
        "    bw = skimage.color.rgb2gray(img)\n",
        "    \n",
        "    # Threshold the image using OTSU threshold\n",
        "    thresh = threshold_otsu(bw)\n",
        "    bw = closing(bw < thresh, square(3)).astype(int)\n",
        "    \n",
        "    # Get the regions in the image.\n",
        "    # This creates a list of regions in the image where the digit possibly is.\n",
        "    regions = regionprops(bw)\n",
        "\n",
        "    # TODO:  Find region with the largest area.  You can get the region area from region.area.\n",
        "    region_max = region.area(regions)\n",
        "     \n",
        "    # Raise an ImgException if no region with area >= 100 was found\n",
        "    if (area_max < 100):\n",
        "        raise ImgException(\"No image found\")    \n",
        "                \n",
        "    # Get the bounding box of the character from region_max.bbox\n",
        "    minr, minc, maxr, maxc = region_max.bbox\n",
        "    box = [minr,minc,maxr,maxc]\n",
        "    \n",
        "    # TODO:  Crop the image in bw to the bounding box\n",
        "    bw_crop = bw[box]\n",
        "        \n",
        "    # TODO:  Resize the cropped image to a 20x20 using the resize command.\n",
        "    # You will need to use the mode = 'constant' option\n",
        "    bw_resize = bw_crop.resize([nx_img, ny_img], mode='constant')\n",
        "    \n",
        "    # TODO:  Threshold back to a 0-1 image by comparing the pixels to their mean value\n",
        "    \n",
        "    # TODO:  Place extracted 20 x 20 image in larger image 28 x 28\n",
        "    # img1 = ...\n",
        "    return img1, box"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now test the `mnist_resize` program by completing the following code.  Create two subplots:\n",
        "* subplot(1,2,1):  The original image with the bounding box for the character that was found in the image.\n",
        "* subplot(1,2,2):  The MNIST resized image."
      ],
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an image\n",
        "img = load_img(13,9)\n",
        "\n",
        "try:\n",
        "    # Resize the image\n",
        "    # img1, box = mnist_resize(img)\n",
        "    \n",
        "    # TODO:  Plot the original image, img, along with a red box around the captured character.\n",
        "    # Use the mpatches.Rectangle and ax.add_patch methods to construct the rectangle.\n",
        "   \n",
        "    # TODO:  Plot the resized 28 x 28 image, img1.  You can use the plt_digit(img1) command \n",
        "       \n",
        "except ImgException as e:\n",
        "    print(e.msg)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, run the command `nlet=1000` times to get 1000 letter images.  In each iteration, select a random image from a lowercase letter and add it to a matrix `Xlet`. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensions\n",
        "nlet = 1000\n",
        "nrow = 28\n",
        "ncol = 28\n",
        "npix = nrow*ncol\n",
        "Xlet = np.zeros((nlet, npix))\n",
        "\n",
        "i = 0\n",
        "while i < nlet:\n",
        "    # TODO:  Generate a random character and sample    \n",
        "    # char_ind = random number corresponding to a lowercase letter except 'O' and 'I'\n",
        "    # samp_ind = random number from 0 to 49\n",
        "  \n",
        "        \n",
        "    try:\n",
        "        # TODO:  Load the image with load_img function\n",
        "        # img = ...\n",
        "        \n",
        "        # TODO:  Reize the image with mnist_resize function\n",
        "        # img1, box = ...\n",
        "        \n",
        "        # TODO:  Store the image in a row of Xlet[i,:] and increment i\n",
        "        i += 1\n",
        "        \n",
        "        # Print progress\n",
        "        if (i % 50 == 0):\n",
        "            print ('images captured = {0:d}'.format(i))\n",
        "    except ImgException:\n",
        "        # Skip if image loading or resizing failed\n",
        "        pass"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images captured = 50\n",
            "images captured = 100\n",
            "images captured = 150\n",
            "images captured = 200\n",
            "images captured = 250\n",
            "images captured = 300\n",
            "images captured = 350\n",
            "images captured = 400\n",
            "images captured = 450\n",
            "images captured = 500\n",
            "images captured = 550\n",
            "images captured = 600\n",
            "images captured = 650\n",
            "images captured = 700\n",
            "images captured = 750\n",
            "images captured = 800\n",
            "images captured = 850\n",
            "images captured = 900\n",
            "images captured = 950\n",
            "images captured = 1000\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this takes a long time to generate, save the matrix `Xlet` to a file `Xlet.p` using the `pickle.dump` command."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n# TODO"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reload the data `Xlet` from the file `Xlet.p`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Extended Training Data\n",
        "\n",
        "Now, create an extended data set by combining `ndig=5000` randomly selected digit samples and `nlet=1000` letters. \n",
        "* Select `ndig=5000` random samples from `Xdigs` and their labels in `ydig`.\n",
        "* Rescale the letters `Xlet` to a new matrix `Xlets = 2*Xlet-1` to make the pixel values go from -1 to 1.\n",
        "* Use the `np.vstack` command to create a 6000 element alpha-numeric data set `X`\n",
        "* Create a corresponding label vector `y` where all the non-digit characters are labeled with a non-digit label, `letter_lbl=10`.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# X = ...  Array with 6000 characters (5000 digits + 1000 letters)\n",
        "# y = ...  Array with 6000 labels (0-9 for the digits, 10 = non-digit)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the SVM classifier\n",
        "\nFirst create the SVM classifer.  Use an \"rbf\" classifier with `C=2.8` and `gamma=.0073`.  Not sure if these are the best parameters, you could try to search for better ones."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "# TODO:  Create a classifier: a support vector classifier\n",
        "# svc = ..."
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get 5000 training samples `Xtr,ytr` and 1000 test samples `Xts,yts`.  Remember to randomly select them."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# Xtr = ...\n",
        "# ytr = ...\n",
        "# Xts = ...\n",
        "# yts = ..."
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `svc.fit` command to fit on the training data.  This may take a few minutes"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measure the accuracy on the test samples.  You should get about 96% accuracy.  You can get better by using more training samples, but it will just take longer to run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the normalized confusion matrix"
      ],
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting some error samples\n",
        "\nWe now plot some errors.  Plot up to four images where yhat == 10 but yts != 10.  That is, the true image was a digit, but the classifier classified it as a non-digit.  Note there may be less than four such errors (when I ran it I got only three such errors).  In that case, just plot only the errors you got.  If there are no errors, print \"No such error found\""
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now plot up to four images where yhat != 10, but yts == 10.  That is, the image was a non-digit, but the classifier thought it was an image.  I happened to get no such images.  If you find no such examples, print \"No such error found\"."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, plot up to four images where yts != yhat and both yts < 10 and yhat < 10."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.2",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}